{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RD-comparison of \"Stereo\" Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import math\n",
    "import zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y, xlabel='', ylabel='', title=''):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.grid()\n",
    "    ax.xaxis.set_label_text(xlabel)\n",
    "    ax.yaxis.set_label_text(ylabel)\n",
    "    ax.plot(x, y, '.', markersize=1)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce some sound ... for example, say something during 5 s\n",
    "This sound will be used to compare the RD performance of the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44100\n",
    "duration = 5.0  # seconds\n",
    "x = sd.rec(int(duration * fs), samplerate=fs, channels=2, dtype=np.int16)\n",
    "print(\"Say something!\")\n",
    "while sd.wait():\n",
    "    pass\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd.play(x)\n",
    "plot(np.linspace(0, len(x)-1, len(x)), x, \"Time\", \"Amplitude\", \"Audio Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = x[151000:152000]\n",
    "plot(np.linspace(0, len(chunk)-1, len(chunk)), chunk, \"Time\", \"Amplitude\", \"Audio Signal (zoom)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "channel_0 = x[:, 0]\n",
    "sd.play(channel_0)\n",
    "plot(np.linspace(0, len(channel_0)-1, len(channel_0)), channel_0, \"Time\", \"Amplitude\", \"Channel 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = x[:, 1]\n",
    "sd.play(channel_1)\n",
    "plot(np.linspace(0, len(channel_1)-1, len(channel_1)), channel_1, \"Time\", \"Amplitude\", \"Channel 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = channel_0 - channel_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(differences)\n",
    "plot(np.linspace(0, len(differences)-1, len(differences)), differences, \"Time\", \"Amplitude\", \"Channel 0 - Channel 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = channel_0 - differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_channel_1 = x[:, 1]\n",
    "sd.play(recons_channel_1)\n",
    "plot(np.linspace(0, len(recons_channel_1)-1, len(recons_channel_1)), recons_channel_1, \"Time\", \"Amplitude\", \"Reconstructed Channel 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1.all() == recons_channel_1.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_energy(x):\n",
    "    #return np.sum(x[:, 0].astype(np.double)*x[:, 0].astype(np.double))/len(x[:, 0]) + \\\n",
    "    #       np.sum(x[:, 1].astype(np.double)*x[:, 1].astype(np.double))/len(x[:, 1])\n",
    "    return np.sum(x.astype(np.double)*x.astype(np.double))/len(x)\n",
    "    \n",
    "def RMSE(x, y):\n",
    "    error_signal = x - y\n",
    "    return math.sqrt(average_energy(error_signal))\n",
    "\n",
    "# Based on https://stackoverflow.com/questions/15450192/fastest-way-to-compute-entropy-in-python\n",
    "def entropy_in_bits_per_symbol(sequence_of_symbols):\n",
    "    value, counts = np.unique(sequence_of_symbols, return_counts = True)\n",
    "    probs = counts / len(sequence_of_symbols)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    entropy = 0.\n",
    "    for i in probs:\n",
    "        entropy -= i * math.log(i, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def deadzone_quantizer(x, quantization_step):\n",
    "    k = (x / quantization_step).astype(np.int)\n",
    "    return k\n",
    "\n",
    "def deadzone_dequantizer(k, quantization_step):\n",
    "    y = quantization_step * k\n",
    "    return y\n",
    "\n",
    "def deadzone_qdeq(x, quantization_step):\n",
    "    k = deadzone_quantizer(x, quantization_step)\n",
    "    y = deadzone_dequantizer(k, quantization_step)\n",
    "    return k, y\n",
    "\n",
    "def RD_curve(chunk, analyze, synthesize):\n",
    "    RD_points = []\n",
    "    for q_step in range(16, 1024, 32):\n",
    "        analyzed_chunk = analyze(chunk)\n",
    "        k, y = deadzone_qdeq(analyzed_chunk, q_step)\n",
    "        rate = entropy_in_bits_per_symbol(k[:, 0]) + entropy_in_bits_per_symbol(k[:, 1])\n",
    "        reconstructed_chunk = synthesize(y)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "    return RD_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Karhunen-LoÃ©ve Transform (KLT)](https://en.wikipedia.org/wiki/Karhunen%E2%80%93Lo%C3%A8ve_theorem), [Hadamard](https://en.wikipedia.org/wiki/Hadamard_transform) and [Haar](https://en.wikipedia.org/wiki/Haar_wavelet#Haar_matrix)\n",
    "\n",
    "The rows (i.e., the [basis](https://en.wikipedia.org/wiki/Basis_(linear_algebra)) vectors) of the of the [discrete](https://en.wikipedia.org/wiki/Discrete_transform) (all transforms discussed in this document are discrete) KLT consist of the [eigenvectors](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#:~:text=In%20linear%20algebra%2C%20an%20eigenvector,which%20the%20eigenvector%20is%20scaled.) of the [autorrelation matrix](https://en.wikipedia.org/wiki/Autocorrelation#Auto-correlation_of_random_vectors) (also known as the [covariance](https://en.wikipedia.org/wiki/Covariance) matrix) of the transformed signal. In block-based transform coding (such as it happens in IterCom in which the audio signal is splitted into chunk) it can be assumed that, on average, the amount of information provided by a subband (the set of coefficients that correspond to a given frequency) is proportional to the variance in this subband.\n",
    "\n",
    "The KLT minize the [geometric mean](https://en.wikipedia.org/wiki/Geometric_mean) of the variance of the transform coefficients. Hence, the KLT provides optimum energy concentration and therefore, the largest [transformation coding gain (TG)](/http://ws2.binghamton.edu/fowler/fowler%20personal%20page/EE523_files/Ch_13_3%20Transform%20Coding%20-%20Coding%20Gain%20&%20Classic%20Transforms%20(PPT).pdf) of any linear transform coding method. Unfortunately, the autocorrelation matrix depends on the transformed signal and therefore, the [change of basis](https://en.wikipedia.org/wiki/Change_of_basis) (the transform) provided by the KLT is signal dependent (each signal needs to be transformed by a different transform matrix), except in the case of 2-samples [block coding](https://web.stanford.edu/class/ee368b/Handouts/11-TransformCoding.pdf).\n",
    "\n",
    "The TG is defined as the ratio of the arithmetic mean of the variances of the coefficients to their geometric means:\n",
    "\n",
    "\\begin{equation}\n",
    "G_{TC} = \\frac{\\frac{1}{N}\\sum_{i=1}^N{\\sigma_i^2}}{(\\prod_{i=1}^N\\sigma_i^2)^{\\frac{1}{N}}}\n",
    "\\end{equation}\n",
    "\n",
    "In the context of signal compression, variance, energy, entropy and information are synonymous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCG(variances):\n",
    "    N = len(variances)\n",
    "    arithmetic_mean = np.sum(variances)/N\n",
    "    geometric_mean = np.prod(variances)**(1/N)\n",
    "    if geometric_mean == 0:\n",
    "        geometric_mean = 1\n",
    "    transform_coding_gain = arithmetic_mean/geometric_mean\n",
    "    return transform_coding_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward transform:\n",
    "#\n",
    "#  [w[0]] = 1/sqrt(2) [1  1] [x[0]]\n",
    "#  [w[1]]             [1 -1] [x[1]]\n",
    "def KLT_analyze(x):\n",
    "    w = np.empty_like(x, dtype=np.int32)\n",
    "    w[:, 0] = np.rint((x[:, 0].astype(np.int32) + x[:, 1]) / math.sqrt(2)) # L\n",
    "    w[:, 1] = np.rint((x[:, 0].astype(np.int32) - x[:, 1]) / math.sqrt(2)) # H\n",
    "    return w\n",
    "\n",
    "# Inverse transform:\n",
    "#\n",
    "#  [x[0]] = 1/sqrt(2) [1  1] [w[0]]\n",
    "#  [x[1]]             [1 -1] [w[1]]\n",
    "def KLT_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    #x[:, 0] = np.rint((w[:, 0] + w[:, 1]) / math.sqrt(2)) # L(ow frequency subband)\n",
    "    #x[:, 1] = np.rint((w[:, 0] - w[:, 1]) / math.sqrt(2)) # H(igh frequency subband)\n",
    "    x[:, :] = KLT_analyze(w)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Mid/Side Transform (MST)](https://en.wikipedia.org/wiki/Joint_encoding#M/S_stereo_coding)\n",
    "\n",
    "MST transforms the left and right channels into a *mid* channel and a *side* channel. The mid channel is the sum of the left and right channels, or $M=L+R$. The side channel is the difference of the left and right channels, or $S=L-R$. See also Section 2.2.1. *Sum-Difference coding* at this [PhD thesis](https://research.tue.nl/en/studentTheses/stereo-coding-by-two-channel-linear-prediction-and-rotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward transform:\n",
    "#\n",
    "#  [w[0]] = [1  1] [x[0]]\n",
    "#  [w[1]]   [1 -1] [x[1]]\n",
    "\n",
    "def MST_analyze(x):\n",
    "    w = np.empty_like(x, dtype=np.int32)\n",
    "    w[:, 0] = x[:, 0].astype(np.int32) + x[:, 1] # L(ow frequency subband)\n",
    "    w[:, 1] = x[:, 0].astype(np.int32) - x[:, 1] # H(igh frequency subband)\n",
    "    return w\n",
    "\n",
    "# Inverse transform:\n",
    "#\n",
    "#  [x[0]] = 1/2 [1  1] [w[0]]\n",
    "#  [x[1]]       [1 -1] [w[1]]\n",
    "\n",
    "def MST_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    x[:, 0] = (w[:, 0] + w[:, 1])/2 # L(ow frequency subband)\n",
    "    x[:, 1] = (w[:, 0] - w[:, 1])/2 # H(igh frequency subband)\n",
    "    return x\n",
    "\n",
    "# This solution is slower than the previous one because: (1) an array of int32 is allocated,\n",
    "# and (2) the memory locality is smaller (the division by 2 is not performed just when\n",
    "# the samples are accesed).\n",
    "def _MST_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    x[:, :] = MST_analyze(w)\n",
    "    x = x / 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = MST_analyze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(np.linspace(0, len(w)-1, len(w)), w[:, 0], \"Time\", \"Amplitude\", \"Mid Channel\")\n",
    "sd.play(w[:, 0].astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(np.linspace(0, len(w)-1, len(w)), w[:, 1], \"Time\", \"Amplitude\", \"Side Channel\")\n",
    "sd.play(w[:, 1].astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Spectrogram of the original chanels')\n",
    "plt.specgram(x[:, 0], Fs=44100)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(212)\n",
    "plt.specgram(x[:, 1],Fs=44100)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Spectrogram of the Mid/Side channels')\n",
    "plt.specgram(w[:, 0], Fs=44100)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(212)\n",
    "plt.specgram(w[:, 1], Fs=44100)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "K1 = np.array([1.0, 1.0])\n",
    "w1, h1 = signal.freqz(K1, fs=44100)\n",
    "K2 = np.array([1.0, -1.0])\n",
    "w2, h2 = signal.freqz(K2, fs=44100)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title('Mid/Side filters frequency responses')\n",
    "plt.plot(w1, 20 * np.log10(abs(h1)), 'b')\n",
    "plt.xlabel('Frequency [rad/sample]')\n",
    "plt.ylabel('Amplitude [dB]')\n",
    "plt.subplot(212)\n",
    "plt.plot(w2, 20 * np.log10(abs(h2)), 'b')\n",
    "plt.xlabel('Frequency [rad/sample]')\n",
    "plt.ylabel('Amplitude [dB]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the cutoff frequency of these filters (Mid is a low-pass filter and Side is a high-pass filter) is very vage, in the sense that the transision between the pass band and the stop band is very wide. This implies that these filter are quite uneffective, as filters. However, this is the maximum performance that we can get using only two coeffients (or taps)/filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MST vs KLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MST_RD_points = RD_curve(x, MST_analyze, MST_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLT_RD_points = RD_curve(x, KLT_analyze, KLT_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bits per sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MST_RD_points), c='b', marker=\"+\", label='MST')\n",
    "plt.scatter(*zip(*KLT_RD_points), c='r', marker=\"x\", label='KLT')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit MST_synthesize(MST_analyze(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit KLT_synthesize(KLT_analyze(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, MST and KLT are equivalent from a R/D perspective. However, MST is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LH = MST_analyze(x)\n",
    "L = LH[:, 0]\n",
    "H = LH[:, 1]\n",
    "variances = [None]*2\n",
    "variances[0] = np.var(L)\n",
    "variances[1] = np.var(H)\n",
    "print(TCG(variances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LH = KLT_analyze(x)\n",
    "L = LH[:, 0]\n",
    "H = LH[:, 1]\n",
    "variances = [None]*2\n",
    "variances[0] = np.var(L)\n",
    "variances[1] = np.var(H)\n",
    "print(TCG(variances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TCG of the KLT is sliiiightly better than the TCG of the MSC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S Transform (ST)\n",
    "In-place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.researchgate.net/profile/Amir_Said2/publication/2598141_Reversible_Image_Compression_Via_Multiresolution_Representation_and_Predictive_Coding/links/56952cf008ae820ff074a536/Reversible-Image-Compression-Via-Multiresolution-Representation-and-Predictive-Coding.pdf\n",
    "#\n",
    "# Forward transform:\n",
    "#\n",
    "#  w[0] = ceil((x[0] + x[1])/2)\n",
    "#  w[1] = x[0] - x[1] \n",
    "#\n",
    "# Inverse transform:\n",
    "#\n",
    "#  x[0] = w[0] + ceil((w[1]+1)/2)\n",
    "#  x[1] = x[0] - w[1]\n",
    "\n",
    "def ST_analyze(x):\n",
    "    w = np.empty_like(x, dtype=np.int32)\n",
    "    w[:, 0] = np.ceil((x[:, 0].astype(np.int32) + x[:, 1])/2)\n",
    "    w[:, 1] = x[:, 0].astype(np.int32) - x[:, 1]\n",
    "    return w\n",
    "\n",
    "def ST_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    x[:, 0] = w[:, 0] + np.ceil((w[:, 1] + 1)/2)\n",
    "    x[:, 1] = x[:, 0] - w[:, 1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ST vs MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_RD_points = RD_curve(x, ST_analyze, ST_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bits per sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MST_RD_points), c='b', marker=\"+\", label='MSC')\n",
    "plt.scatter(*zip(*ST_RD_points), c='r', marker=\"x\", label='ST')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MST performs slighly better than ST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_DEFLATE_RD_curve(chunk, analyze, synthesize):\n",
    "    RD_points = []\n",
    "    for q_step in range(16, 1024, 32):\n",
    "        analyzed_chunk = analyze(chunk)\n",
    "        k, y = deadzone_qdeq(analyzed_chunk, q_step)\n",
    "        subband_0 = k[:, 0].copy()\n",
    "        subband_1 = k[:, 1].copy()\n",
    "        rate = len(zlib.compress(subband_0)) + len(zlib.compress(subband_1))\n",
    "        #rate = entropy_in_bits_per_symbol(k[:, 0]) + entropy_in_bits_per_symbol(k[:, 1])\n",
    "        reconstructed_chunk = synthesize(y)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "    return RD_points\n",
    "\n",
    "def _stereo_DEFLATE_RD_curve(chunk, analyze, synthesize):\n",
    "    ch0_RD_points = []\n",
    "    ch1_RD_points = []\n",
    "    for q_step in range(16, 1024, 32):\n",
    "        analyzed_chunk = analyze(chunk)\n",
    "        k, y = deadzone_qdeq(analyzed_chunk, q_step)\n",
    "        tmp = y.copy()\n",
    "        y[:, 1] = 0\n",
    "        \n",
    "        reconstructed_chunk_with_subband_0 = synthesize(y)\n",
    "        distortion_only_subband_0 = RMSE(chunk, reconstructed_chunk_with_subband_0)\n",
    "        rate_subband_0 = len(zlib.compress(k[:, 0].copy()))\n",
    "        ch0_RD_points.append((rate_subband_0, distortion_only_subband_0))\n",
    "        \n",
    "        y = tmp.copy()\n",
    "        y[:, 0] = 0\n",
    "        #y[:, 1] = 0\n",
    "        reconstructed_chunk_with_subband_1 = synthesize(y)\n",
    "        distortion_only_subband_1 = RMSE(chunk, reconstructed_chunk_with_subband_1)\n",
    "        rate_subband_1 = len(zlib.compress(k[:, 1].copy()))\n",
    "        ch1_RD_points.append((rate_subband_1, distortion_only_subband_1))\n",
    "    return [ch0_RD_points, ch1_RD_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MST_RD_points = stereo_DEFLATE_RD_curve(x, MST_analyze, MST_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bytes\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MST_RD_points), c='b', marker=\"+\", label='MSC')\n",
    "#plt.scatter(*zip(*KLT_RD_points), c='r', marker=\"x\", label='KLT')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MST_RD_points = _stereo_DEFLATE_RD_curve(x, MST_analyze, MST_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"RD comparative\")\n",
    "plt.xlabel(\"Bytes\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MST_RD_points[0]), c='b', marker=\"+\", label='channel 0')\n",
    "plt.scatter(*zip(*MST_RD_points[1]), c='r', marker=\"+\", label='channel 1')\n",
    "#plt.scatter(*zip(*KLT_RD_points), c='r', marker=\"x\", label='KLT')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_min_rate = min(MST_RD_points[0][:])[0]\n",
    "mid_max_rate = max(MST_RD_points[0][:])[0]\n",
    "mid_min_distortion = min(MST_RD_points[0][:])[1]\n",
    "mid_max_distortion = max(MST_RD_points[0][:])[1]\n",
    "print(mid_min_rate, mid_max_rate, mid_min_distortion, mid_max_distortion)\n",
    "\n",
    "side_min_rate = min(MST_RD_points[1][:])[0]\n",
    "side_max_rate = max(MST_RD_points[1][:])[0]\n",
    "side_min_distortion = min(MST_RD_points[1][:])[1]\n",
    "side_max_distortion = max(MST_RD_points[1][:])[1]\n",
    "print(side_min_rate, side_max_rate, side_min_distortion, side_max_distortion)\n",
    "\n",
    "#min_rate = min(mid_min_rate, side_min_rate)\n",
    "max_rate = max(mid_max_rate, side_max_rate)\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(*zip(*MST_RD_points[0]), c='b', marker=\"+\", label='channel 0')\n",
    "plt.title('Only Mid Channel')\n",
    "plt.xlabel('Bytes')\n",
    "plt.ylabel('RMSE')\n",
    "#plt.xlim(0, max_rate)\n",
    "plt.ylim(mid_max_distortion, mid_min_distortion)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(*zip(*MST_RD_points[1]), c='r', marker=\"+\", label='channel 1')\n",
    "plt.title('Only Side Channel')\n",
    "plt.xlabel('Bytes')\n",
    "#plt.xlim(0, max_rate)\n",
    "#plt.ylim(4957, 5027)\n",
    "#plt.ylabel('RMSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quantization?\n",
    "\n",
    "We compare two quantizations of the decomposition. First, $\\Delta_1 = \\Delta_2$. Next, $\\Delta_1 = \\sqrt{2}\\Delta_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_DEFLATE_RD_curve_same_delta(chunk, analyze, synthesize):\n",
    "    RD_points = []\n",
    "    for q_step in range(16, 1024, 32):\n",
    "        analyzed_chunk = analyze(chunk)\n",
    "        k, y = deadzone_qdeq(analyzed_chunk, q_step)\n",
    "        k_0 = k[:, 0].copy()\n",
    "        k_1 = k[:, 1].copy()\n",
    "        rate = len(zlib.compress(k_0)) + len(zlib.compress(k_1))\n",
    "        #rate = entropy_in_bits_per_symbol(k[:, 0]) + entropy_in_bits_per_symbol(k[:, 1])\n",
    "        #print(y)\n",
    "        reconstructed_chunk = synthesize(y)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "        #RD_points.append((q_step, distortion))\n",
    "    return RD_points\n",
    "\n",
    "def stereo_DEFLATE_RD_curve_different_delta(chunk, analyze, synthesize):\n",
    "    RD_points = []\n",
    "    for q_step in range(16, 1024, 32):\n",
    "        analyzed_chunk = analyze(chunk)\n",
    "        subband_0 = analyzed_chunk[:, 0].copy()\n",
    "        subband_1 = analyzed_chunk[:, 1].copy()\n",
    "        #k_0, y_0 = deadzone_qdeq(subband_0, int(1000.0*q_step))\n",
    "        k_0, y_0 = deadzone_qdeq(subband_0, q_step)\n",
    "        k_1, y_1 = deadzone_qdeq(subband_1, int(1000.0*q_step))\n",
    "        #k_1, y_1 = deadzone_qdeq(subband_1, q_step)\n",
    "        rate = len(zlib.compress(k_0)) + len(zlib.compress(k_1))\n",
    "        y = np.empty_like(x, dtype=np.int32)\n",
    "        y[:, 0] = y_0\n",
    "        y[:, 1] = y_1\n",
    "        reconstructed_chunk = synthesize(y)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "    return RD_points\n",
    "\n",
    "def stereo_DEFLATE_RD_curve_different_delta_b(chunk, analyze, synthesize):\n",
    "    RD_points = []\n",
    "    for q_step in range(16, 1024, 32):\n",
    "        analyzed_chunk = analyze(chunk)\n",
    "        subband_0 = analyzed_chunk[:, 0].copy()\n",
    "        subband_1 = analyzed_chunk[:, 1].copy()\n",
    "        k_0, y_0 = deadzone_qdeq(subband_0, 256)\n",
    "        k_1, y_1 = deadzone_qdeq(subband_1, q_step)\n",
    "        rate = len(zlib.compress(k_0)) + len(zlib.compress(k_1))\n",
    "        y = np.empty_like(x, dtype=np.int32)\n",
    "        y[:, 0] = y_0\n",
    "        y[:, 1] = y_1\n",
    "        reconstructed_chunk = synthesize(y)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "        #RD_points.append((q_step, distortion))\n",
    "    return RD_points\n",
    "\n",
    "def stereo_DEFLATE_RD_curve_different_delta_c(chunk, analyze, synthesize):\n",
    "    RD_points = []\n",
    "    analyzed_chunk = analyze(chunk)\n",
    "    subband_0 = analyzed_chunk[:, 0].copy()\n",
    "    subband_1 = analyzed_chunk[:, 1].copy()\n",
    "    k_0, y_0 = deadzone_qdeq(subband_0, 256)\n",
    "    k_1, y_1 = deadzone_qdeq(subband_1, 256)\n",
    "    rate = len(zlib.compress(k_0)) + len(zlib.compress(k_1))\n",
    "    y = np.empty_like(x, dtype=np.int32)\n",
    "    y[:, 0] = y_0\n",
    "    y[:, 1] = y_1\n",
    "    reconstructed_chunk = synthesize(y)\n",
    "    distortion = RMSE(chunk, reconstructed_chunk)\n",
    "    RD_points.append((rate, distortion))\n",
    "    return RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MST_RD_points_same_delta = stereo_DEFLATE_RD_curve_same_delta(x, MST_analyze, MST_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MST_RD_points_different_delta = stereo_DEFLATE_RD_curve_different_delta_b(x, MST_analyze, MST_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MST_RD_points_different_delta_c = stereo_DEFLATE_RD_curve_different_delta_c(x, MST_analyze, MST_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bits per sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MST_RD_points_same_delta), c='b', marker=\".\", label='$\\Delta_1=\\Delta_2$')\n",
    "plt.scatter(*zip(*MST_RD_points_different_delta), c='r', marker=\".\", label='$\\Delta_1=\\sqrt{2}\\Delta_2$')\n",
    "plt.scatter(*zip(*MST_RD_points_different_delta_c), c='g', marker=\"o\", label='$\\Delta_1=\\sqrt{2}\\Delta_2$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSC/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward transform:\n",
    "#\n",
    "#  [w[0]] = 1/2 [1  1] [x[0]]\n",
    "#  [w[1]]       [1 -1] [x[1]]\n",
    "#\n",
    "# Inverse transform:\n",
    "#\n",
    "#  [x[0]] = [1  1] [w[0]]\n",
    "#  [x[1]]   [1 -1] [w[1]]\n",
    "\n",
    "def _MSC2_analyze(x):\n",
    "    w = np.empty_like(x, dtype=np.int32)\n",
    "    w[:, 0] = (x[:, 0].astype(np.int32) + x[:, 1])/2 # L(ow frequency subband)\n",
    "    w[:, 1] = (x[:, 0].astype(np.int32) - x[:, 1])/2 # H(igh frequency subband)\n",
    "    #w[:, 0] = w[:, 0] / 2\n",
    "    return w\n",
    "\n",
    "def MSC2_analyze(x):\n",
    "    w = np.empty_like(x, dtype=np.int32)\n",
    "    w[:, 0] = (x[:, 0].astype(np.int32) + x[:, 1])/2 # L(ow frequency subband)\n",
    "    w[:, 1] = (x[:, 0].astype(np.int32) - x[:, 1])/2 # H(igh frequency subband)\n",
    "    #w[:, 0] = w[:, 0] / 2\n",
    "    return w\n",
    "\n",
    "def _MSC2_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    #w[:, 0] = w[:, 0] * 2\n",
    "    x[:, :] = MSC2_analyze(w)\n",
    "    return x\n",
    "\n",
    "def MSC2_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    x[:, 0] = w[:, 1] + x[:, 1]\n",
    "    x[:, 1] = w[:, 0] - x[:, 0]\n",
    "    #w[:, 0] = w[:, 0] * 2\n",
    "    #x[:, :] = MSC2_analyze(w)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSC vs MSC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSC2_RD_points = RD_curve(x, MSC2_analyze, MSC2_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bits per sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MSC_RD_points), c='b', marker=\"+\", label='MSC')\n",
    "plt.scatter(*zip(*MSC2_RD_points), c='r', marker=\"x\", label='MSC2')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit MSC2_synthesize(MSC2_analyze(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?? transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward transform:\n",
    "#\n",
    "#  [w[0]] = 1/2 [1  1] [x[0]]\n",
    "#  [w[1]]       [1 -1] [x[1]]\n",
    "#\n",
    "# Inverse transform:\n",
    "#\n",
    "#  [x[0]] = [1  1] [w[0]]\n",
    "#  [x[1]]   [1 -1] [w[1]]\n",
    "#\n",
    "# Forward transform:\n",
    "#\n",
    "#  w[1] = x[0] - x[1] \n",
    "#  w[0] = x[0] - w[1]/2\n",
    "#  w[1] /= 2\n",
    "#\n",
    "# Inverse transform:\n",
    "#\n",
    "#  w[1] *= 2\n",
    "#  x[0] = w[0] + w[1]/2\n",
    "#  x[1] = x[0] - w[1]\n",
    "\n",
    "def orig2_analyze(x):\n",
    "    w = np.empty_like(x, dtype=np.int32)\n",
    "    w[:, 1] = x[:, 0].astype(np.int32) - x[:, 1]\n",
    "    w[:, 0] = x[:, 0] - w[:, 1] / 2\n",
    "    w[:, 1] = w[:, 1] / 2\n",
    "    return w\n",
    "\n",
    "def orig2_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    w[:, 1] = w[:, 1] * 2\n",
    "    x[:, 0] = w[:, 0] + w[:, 1]/2\n",
    "    x[:, 1] = x[:, 0] - w[:, 1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig2_RD_points = RD_curve(x, orig2_analyze, orig2_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bits per sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MSC_RD_points), c='b', marker=\"+\", label='MSC')\n",
    "plt.scatter(*zip(*orig2_RD_points), c='r', marker=\"x\", label='?')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit orig2_synthesize(orig2_analyze(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ? transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward transform:\n",
    "#\n",
    "#  w[1] = x[1] - x[0] \n",
    "#  w[0] = x[0] + w[1]/2\n",
    "#  w[1] /= 2\n",
    "#\n",
    "# Inverse transform:\n",
    "#\n",
    "#  w[1] *= 2\n",
    "#  x[0] = w[0] - w[1]/2\n",
    "#  x[1] = x[0] + w[1]\n",
    "\n",
    "def orig_analyze(x):\n",
    "    w = np.empty_like(x, dtype=np.int32)\n",
    "    w[:, 1] = x[:, 1].astype(np.int32) - x[:, 0]\n",
    "    w[:, 0] = x[:, 0] + np.rint(w[:, 1] / 2)\n",
    "    w[:, 1] = np.rint(w[:, 1] / 2)\n",
    "    return w\n",
    "\n",
    "def orig_synthesize(w):\n",
    "    x = np.empty_like(w, dtype=np.int16)\n",
    "    w[:, 1] = w[:, 1] * 2\n",
    "    x[:, 0] = w[:, 0] - np.rint(w[:, 1]/2)\n",
    "    x[:, 1] = w[:, 1] + x[:, 0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_RD_points = RD_curve(x, orig_analyze, orig_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bits per sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MSC_RD_points), c='b', marker=\"+\", label='MSC')\n",
    "plt.scatter(*zip(*orig_RD_points), c='r', marker=\"x\", label='?')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction to Data Compression (Sayood), pag. 402\n",
    "\n",
    "def pordeterminar_analyze(chunk):\n",
    "    analyzed_chunk = np.empty_like(chunk, dtype=np.int16)\n",
    "    analyzed_chunk[:, 1] = chunk[:, 1] - chunk[:, 0]\n",
    "    analyzed_chunk[:, 0] = chunk[:, 0] + np.rint(analyzed_chunk[:, 1]/2)\n",
    "    return analyzed_chunk\n",
    "\n",
    "def pordeterminar_synthesize(analyzed_chunk):\n",
    "    chunk = np.empty_like(analyzed_chunk, dtype=np.int16)\n",
    "    chunk[:, 0] = analyzed_chunk[:, 0] - np.rint(analyzed_chunk[:, 1]/2)\n",
    "    chunk[:, 1] = analyzed_chunk[:, 1] + chunk[:, 0]\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig2_analyze(chunk):\n",
    "    analyzed_chunk = np.empty_like(chunk, dtype=np.int16)\n",
    "    analyzed_chunk[:, 1] = chunk[:, 1] - chunk[:, 0]\n",
    "    analyzed_chunk[:, 0] = (chunk[:, 0] + chunk[:, 1]) // 2\n",
    "    return analyzed_chunk\n",
    "\n",
    "def orig2_synthesize(analyzed_chunk):\n",
    "    chunk = np.empty_like(analyzed_chunk, dtype=np.int16)\n",
    "    chunk[:, 1] = analyzed_chunk[:, 0] + analyzed_chunk[:, 1] // 2\n",
    "    chunk[:, 0] = chunk[:, 1] - analyzed_chunk[:, 1]\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig3_analyze(chunk):\n",
    "    analyzed_chunk = np.empty_like(chunk, dtype=np.int16)\n",
    "    analyzed_chunk[:, 1] = chunk[:, 1] - chunk[:, 0]\n",
    "    analyzed_chunk[:, 0] = chunk[:, 0] + np.rint(analyzed_chunk[:, 1]/2)\n",
    "    analyzed_chunk[:, 1] = analyzed_chunk[:, 1] // 2\n",
    "    return analyzed_chunk\n",
    "\n",
    "def orig3_synthesize(analyzed_chunk):\n",
    "    chunk = np.empty_like(analyzed_chunk, dtype=np.int16)\n",
    "    analyzed_chunk[:, 1] = analyzed_chunk[:, 1] * 2\n",
    "    chunk[:, 0] = analyzed_chunk[:, 0] - np.rint(analyzed_chunk[:, 1]/2)\n",
    "    chunk[:, 1] = analyzed_chunk[:, 1] + chunk[:, 0]\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_RD_points = RD_curve(x, orig_analyze, orig_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig2_RD_points = RD_curve(x, orig2_analyze, orig2_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig3_RD_points = RD_curve(x, orig3_analyze, orig3_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_RD_points = RD_curve(x, pordeterminar_analyze, pordeterminar_synthesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"R/D comparative\")\n",
    "plt.xlabel(\"Bits per sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*MS_RD_points), c='b', marker=\"o\", label='MS')\n",
    "plt.scatter(*zip(*KLT_RD_points), c='g', marker=\"^\", label='KLT')\n",
    "plt.scatter(*zip(*orig_RD_points), c='r', marker=\"v\", label='orig')\n",
    "plt.scatter(*zip(*orig2_RD_points), c='m', marker=\"x\", label='orig2')\n",
    "plt.scatter(*zip(*orig3_RD_points), c='c', marker=\"h\", label='orig3')\n",
    "plt.scatter(*zip(*pd_RD_points), c='y', marker=\"+\", label='pd')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
