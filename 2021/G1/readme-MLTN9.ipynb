{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hito 9\n",
    "## Comprimiendo con `zlib`\n",
    "\n",
    "Para entender mejor cómo es un `chunk`, hemos hecho una ilustración simple:\n",
    "\n",
    "![estructura-de-un-chunk](https://github.com/RaquelGG/TM/blob/master/otros/transponer1.png?raw=true)\n",
    "### Método `pack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-74bd1cb10ec8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-74bd1cb10ec8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def pack(self, seq, chunk):\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def pack(self, seq, chunk):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos decidido comprobar por nuestra cuenta la diferencia de eficiencia entre separar los canales de cada frame en python, de forma normal o usando `numpy`, para ello usamos `timeit`, que cronometra únicamente la parte `stmt` y en setup creamos un array aleatorio, todos del mismo tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con python: 8.919459699995059 s\n",
      "con numpy slice : 0.1722801000069012 s\n",
      "con numpy transpose : 0.14907310000126017 s\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "py = timeit.timeit(stmt='test[::2]', setup='import os;test=os.urandom(2**15)')\n",
    "np_sliced = timeit.timeit(stmt='test[::2]', setup='import os;import numpy;test=numpy.frombuffer(os.urandom(2**15),dtype=\"int16\")')\n",
    "np_trasposed = timeit.timeit(stmt='test.transpose()', setup='import os;import numpy;test=numpy.frombuffer(os.urandom(2**15),dtype=\"int16\").reshape(-1, 2)')\n",
    "print(\"con python:\", py, \"s\")\n",
    "print(\"con numpy slice :\", np_sliced, \"s\")\n",
    "print(\"con numpy transpose :\", np_trasposed, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejorar la comprensión del código, trasponemos la matriz `chunk`, pasará a ser:\n",
    "\n",
    "![estructura-de-un-chunk](https://github.com/RaquelGG/TM/blob/master/otros/transponer2.png?raw=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [1]],\n",
       "\n",
       "       [[2],\n",
       "        [2]],\n",
       "\n",
       "       [[3],\n",
       "        [3]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "chunk = np.array([[[1], [1]],\n",
    "                  [[2], [2]],\n",
    "                  [[3], [3]]])\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [1, 2, 3]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera solo recorreríamos los canales y queda más legible a la hora de comprimir con `zlib.compress()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "compressed_channels = [zlib.compress(np.ascontiguousarray(channel), level=zlib.Z_BEST_COMPRESSION) for channel in chunk.transpose()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos los datos en una secuencia de bytes que pueden ser enviadas por UDP, añadiendo, adicionalmente, el tamaño del primer canal comprimido (para luego poder diferenciar los canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_format = f\"HH{len(compressed_channels[0])}s{len(compressed_channels[1])}s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último, empaquetamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return struct.pack(\n",
    "    pack_format, \n",
    "    seq, \n",
    "    len(compressed_channels[0]), # tamaño del primer canal comprimido\n",
    "    *compressed_channels, # * es para compressed_channel[0], [1], ... (expande el array)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método `unpack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(self, packed_chunk):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el tamaño del primer canal y del segundo, que se calcula con la diferencia de `packed_chunk` y el tamaño del primer canal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_channel_size, = struct.unpack(\"H\", packed_chunk[SEQ_NO_SIZE:2*SEQ_NO_SIZE])\n",
    "second_channel_size = len(packed_chunk) - first_channel_size - 2*SEQ_NO_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez sabemos el tamaño de ambos canales, podemos desempaquetarlo por completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, _, first_channel_bytes, second_channel_bytes = struct.unpack(\n",
    "    f\"HH{first_channel_size}s{second_channel_size}s\",\n",
    "    packed_chunk,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descomprimimos los canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_channel = np.frombuffer(\n",
    "    zlib.decompress(first_channel_bytes), \n",
    "    dtype='int16',\n",
    ")   \n",
    "second_channel = np.frombuffer(\n",
    "    zlib.decompress(second_channel_bytes),\n",
    "    dtype='int16'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último, volvemos a dejar el chunk con su forma original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ascontiguousarray(np.concatenate((first_channel, second_channel)).reshape(2,-1).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![estructura-de-un-chunk](https://github.com/RaquelGG/TM/blob/master/otros/transponer1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Pruebas\n",
    "En el método `pack()` hemos calculado la tasa de compresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = sum(len(channel) for channel in compressed_channels)\n",
    "print(\"size\", size, \"bytes, compression rate\", \"{:.2f}%\".format(100*(1-size/4096)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como resultado:\n",
    "size 1985 bytes, compression rate 51.54%\n",
    "size 1982 bytes, compression rate 51.61%\n",
    "size 2017 bytes, compression rate 50.76%\n",
    "size 2011 bytes, compression rate 50.90%\n",
    "size 1987 bytes, compression rate 51.49%\n",
    "size 2018 bytes, compression rate 50.73%\n",
    "size 1994 bytes, compression rate 51.32%\n",
    "size 2065 bytes, compression rate 49.58%\n",
    "size 2056 bytes, compression rate 49.80%\n",
    "size 1992 bytes, compression rate 51.37%\n",
    "size 2034 bytes, compression rate 50.34%\n",
    "size 1933 bytes, compression rate 52.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la compresión ha mejorado el tamaño de los paquetes considerablemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprimiendo directamente el chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(self, seq, chunk):\n",
    "    \"\"\"TODO\n",
    "        \"\"\"\n",
    "    compressed_chunk = zlib.compress(chunk.transpose().reshape(-1)) # reshape(-1) deja en una línea el array\n",
    "    size = len(compressed_chunk)\n",
    "    print(\"size\", size, \"bytes, compression rate\", \"{:.2f}%\".format(100*(1-size/4096)))\n",
    "\n",
    "\n",
    "    pack_format = f\"H{len(compressed_chunk)}s\"\n",
    "    return struct.pack(\n",
    "        pack_format, \n",
    "        seq, \n",
    "        compressed_chunk,\n",
    "    )\n",
    "\n",
    "def unpack(self, packed_chunk):\n",
    "    \"\"\"TODO\n",
    "        \"\"\"\n",
    "    seq, compressed_chunk_bytes = struct.unpack(f\"H {len(packed_chunk) - SEQ_NO_SIZE}s\", packed_chunk)\n",
    "        \n",
    "    chunk = np.frombuffer(\n",
    "        zlib.decompress(compressed_chunk_bytes), \n",
    "        dtype='int16',\n",
    "    )\n",
    "\n",
    "    return seq, np.ascontiguousarray(chunk.reshape(2,-1).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size 2112 bytes, compression rate 48.44%\n",
    "size 2046 bytes, compression rate 50.05%\n",
    "size 2009 bytes, compression rate 50.95%\n",
    "size 2128 bytes, compression rate 48.05%\n",
    "size 2067 bytes, compression rate 49.54%\n",
    "size 1975 bytes, compression rate 51.78%\n",
    "size 1997 bytes, compression rate 51.25%\n",
    "size 1947 bytes, compression rate 52.47%\n",
    "size 2057 bytes, compression rate 49.78%\n",
    "size 2025 bytes, compression rate 50.56%\n",
    "size 2061 bytes, compression rate 49.68%\n",
    "size 2216 bytes, compression rate 45.90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pero... ¿Cómo se escucha?\n",
    "Se escucha perfecto, no hay diferencia entre un audio sin comprimir y otro comprimido ya que es una compresión sin pérdidas.\n",
    "\n",
    "![Happy](https://www.freeiconspng.com/uploads/happy-cat-png-0.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
